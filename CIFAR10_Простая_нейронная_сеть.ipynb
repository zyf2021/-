{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjUcCMI4/Va6mIUaG9JYTQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "817252abd7fe4de59b9e35b5470b6ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4239a82f277249cc91a9eb266e680a5d",
              "IPY_MODEL_dfe584d126944711bb745dd688af9a05",
              "IPY_MODEL_70e1c4b8e8604f28800e7494c1d96c18"
            ],
            "layout": "IPY_MODEL_46a40c57d91c4da0a54734e407903eee"
          }
        },
        "4239a82f277249cc91a9eb266e680a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_250f4a59c2d449ce9d1c073ea33a7262",
            "placeholder": "​",
            "style": "IPY_MODEL_b4b60a5970f744489db3d6270dc35e68",
            "value": "100%"
          }
        },
        "dfe584d126944711bb745dd688af9a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58a1e7553a4b42a997479662803ec509",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3941f0209ca643c3a312b4bd1d1a838f",
            "value": 170498071
          }
        },
        "70e1c4b8e8604f28800e7494c1d96c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e45b6b5f5dd54fb18ecbbbe8644f33d8",
            "placeholder": "​",
            "style": "IPY_MODEL_db81c196127b4727bad62b2e870efc2f",
            "value": " 170498071/170498071 [00:02&lt;00:00, 83256924.30it/s]"
          }
        },
        "46a40c57d91c4da0a54734e407903eee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "250f4a59c2d449ce9d1c073ea33a7262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4b60a5970f744489db3d6270dc35e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58a1e7553a4b42a997479662803ec509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3941f0209ca643c3a312b4bd1d1a838f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e45b6b5f5dd54fb18ecbbbe8644f33d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db81c196127b4727bad62b2e870efc2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zyf2021/-/blob/main/CIFAR10_%D0%9F%D1%80%D0%BE%D1%81%D1%82%D0%B0%D1%8F_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*Терпи и читай, проще уже не будет. Отвечаю*"
      ],
      "metadata": {
        "id": "ll40n2ge2_Lf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Полезные и приятные ссылки на пояснения с картинками:**\n",
        "\n",
        "\n",
        "[ML: Введение в PyTorch: 3. Нейронные сети](https://qudata.com/ml/ru/NN_Base_Torch_NN.html#summary)\n",
        "\n",
        "[Объяснение работы CNN](https://qudata.com/ml/ru/NN_CNN_Explainable.html)\n",
        "\n",
        "[WELCOME TO PYTORCH TUTORIALS](https://pytorch.org/tutorials/)\n",
        "\n",
        "**Материалы взяты из источника:** \n",
        "\n",
        "[Обучение модели с помощью PyTorch](https://learn.microsoft.com/ru-ru/windows/ai/windows-ml/tutorials/pytorch-train-model#how-does-a-neural-network-work)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wgyfcauC3LIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Загрузка данных\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "eMbjKdOKw70I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь мы применим набор данных **CIFAR10** для создания и обучения модели классификации. Набор данных CIFAR10 очень широко используется в сфере исследований машинного обучения. Он содержит 50 000 изображений для обучения и еще 10 000 изображений для тестирования. Каждое из них имеет размер 3×32×32 (трехканальный цвет, 32 пикселя в высоту и 32 пикселя в ширину).\n",
        "\n"
      ],
      "metadata": {
        "id": "nsqKWW5muhxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Эти изображения разделены на 10 классов: airplane (0), automobile (1), bird (2), cat (3), deer (4), dog (5), frog (6), horse (7), ship (8), truck (9).\n",
        "\n"
      ],
      "metadata": {
        "id": "2vVgP0W0ul4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для загрузки и чтения набора данных CIFAR10 в PyTorch нужно выполнить **три шага**:\n",
        "\n",
        "\n",
        "1.   **Определите преобразования**, которые будут применяться к изображению. Для обучения модели вам нужно преобразовать изображения в тензоры или привести к нормализованному диапазону [-1,1].\n",
        "2.   Создайте экземпляр доступного **набора данных** и загрузите его. Чтобы загрузить данные, используется абстрактный класс torch.utils.data.Dataset для представления набора данных. Этот набор данных будет скачан на локальный компьютер только при первом выполнении кода.\n",
        "3.   **Доступ к данным** с использованием DataLoader. Чтобы получить доступ к данным и поместить их в память компьютера, используется класс torch.utils.data.DataLoader. DataLoader в PyTorch выполняет роль оболочки для набора данных и предоставляет доступ к базовым данным. Эта оболочка будет содержать пакеты изображений заданного размера.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E3Y7QBgouuq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "U4xbNTrqvJ4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка и нормализация данных. Определение преобразований для тренировочной и тестовой выборки."
      ],
      "metadata": {
        "id": "jKYU-dHH3tF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformations = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "eg-ifD-KvLD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Набор данных CIFAR10 состоит из 50 000 обучающих изображений. Необходимо определить размер пакета 10 для загрузки 5000 пакетов изображений."
      ],
      "metadata": {
        "id": "4scd_Xo9vmQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Batch_size** - это"
      ],
      "metadata": {
        "id": "_b4l-BcQ4DF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "number_of_labels = 10 "
      ],
      "metadata": {
        "id": "MXosVwwavmB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создана копия (экземпляр) для обучения (тренировки)\n",
        "\n",
        "При запуске этого кода в первый раз, тренировочный набор данных (сет, датасет) загружается локально."
      ],
      "metadata": {
        "id": "u0S3Klkfvw3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set =CIFAR10(root=\"./data\",train=True,transform=transformations,download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "817252abd7fe4de59b9e35b5470b6ef8",
            "4239a82f277249cc91a9eb266e680a5d",
            "dfe584d126944711bb745dd688af9a05",
            "70e1c4b8e8604f28800e7494c1d96c18",
            "46a40c57d91c4da0a54734e407903eee",
            "250f4a59c2d449ce9d1c073ea33a7262",
            "b4b60a5970f744489db3d6270dc35e68",
            "58a1e7553a4b42a997479662803ec509",
            "3941f0209ca643c3a312b4bd1d1a838f",
            "e45b6b5f5dd54fb18ecbbbe8644f33d8",
            "db81c196127b4727bad62b2e870efc2f"
          ]
        },
        "id": "YLpKkcV1vfAb",
        "outputId": "6d786cda-6844-46da-e329-8fca42f8d6f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "817252abd7fe4de59b9e35b5470b6ef8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Необходимо создать загрузчик для обучающего набора, который будет считывать данные в пределах размера партии и помещать в память.\n",
        "\n",
        "**DataLoader**"
      ],
      "metadata": {
        "id": "AbLFUOuSwGpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "print(\"The number of images in a training set is: \", len(train_loader)*batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5WeiKmCwCW_",
        "outputId": "6f06a43a-0766-474a-9cb5-0ec1f783d4a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of images in a training set is:  50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create an instance for testing, note that train is set to False.\n",
        "##### When we run this code for the first time, the CIFAR10 test dataset will be downloaded locally. "
      ],
      "metadata": {
        "id": "T5F_w0a3wMUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = CIFAR10(root=\"./data\", train=False, transform=transformations, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7cV_cm2wQYf",
        "outputId": "511f8448-cf4d-425a-ed68-7093f15f4d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create a loader for the test set which will read the data within batch size and put into memory. \n",
        "##### Note that each shuffle is set to false for the test loader."
      ],
      "metadata": {
        "id": "EeEAQK7swUBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "print(\"The number of images in a test set is: \", len(test_loader)*batch_size)\n",
        "\n",
        "print(\"The number of batches per epoch is: \", len(train_loader))\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2qej7bjwTrP",
        "outputId": "cfee649f-7874-481a-e97d-c6154f6397b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of images in a test set is:  10000\n",
            "The number of batches per epoch is:  5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Обучение модели с помощью PyTorch\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5i1XGq_NxDHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для обучения классификатора изображений с помощью PyTorch нужно выполнить следующие действия:\n",
        "1. Загрузите данные. Если вы выполнили задачи на предыдущем этапе этого руководства, значит, эта часть уже готова.\n",
        "2. Определение нейронной сети свертки.\n",
        "3. Определение функции потери.\n",
        "4. Обучение модели по данным для обучения.\n",
        "5. Тестирование модели по данным для проверки.\n"
      ],
      "metadata": {
        "id": "XPIhtqCTxNTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы создать с помощью PyTorch нейронную сеть, используйте пакет` torch.nn.` Этот пакет содержит модули, расширяемые классы и все компоненты, необходимые для создания нейронных сетей."
      ],
      "metadata": {
        "id": "kgYbTseAx74P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Структура нашей сети будет включать следующие 14 слоев:\n",
        "\n",
        "`Conv -> BatchNorm -> ReLU -> Conv -> BatchNorm -> ReLU -> MaxPool -> Conv -> BatchNorm -> ReLU -> Conv -> BatchNorm -> ReLU -> Linear`."
      ],
      "metadata": {
        "id": "7qITXASXx_fX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Слой свертки\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Слой свертки является основным в структуре CNN и предназначен для обнаружения признаков на изображениях. Каждый из слоев содержит несколько каналов, которые обнаруживают определенные виды признаков, а также несколько ядер для определения размера обнаруженных признаков. Таким образом, слой свертки с 64 каналами и размером ядра 3×3 может обнаруживать 64 отдельных признака размером 3×3 каждый. Определяя слой свертки, вам следует указать число входящих каналов, число исходящих каналов и размер ядра. Число исходящих каналов каждого слоя определяет число входящих каналов для следующего слоя.\n",
        "\n",
        "Пример: слой свертки с параметрами `in-channels=3`, `out-channels=10` и `kernel-size=6` будет принимать на вход RGB-изображение (три канала) и применять к изображениям 10 детекторов признаков с размером ядра 6×6. Чем меньше размер ядра, тем быстрее выполняется вычисление и меньше результатов с одинаковым весом.\n",
        "\n",
        "#### Другие слои\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Слои в нашей сети расположены в следующем порядке:\n",
        "\n",
        "* Слой `ReLU` выполняет роль функции активации, которая присваивает всем входящим признакам значения не меньше нуля. При применении этого слоя все отрицательные числа заменяются нулями, а положительные сохраняются без изменений.\n",
        "* Слой `BatchNorm2d` применяет нормализацию входа так, чтобы среднее значение и вариантность элементов стали нулевыми. Это повышает точность работы сети.\n",
        "* Слой `MaxPool` позволяет сделать так, чтобы расположение объекта в изображении не влияло на способность нейронной сети обнаруживать его признаки.\n",
        "* Слои `Linear` завершают структуру нашей сети и используются для вычисления оценки по каждому классу. В наборе данных CIFAR10 присвоены метки десяти классов. Прогнозом модели будет считаться та из этих меток, у которой самая высокая оценка. На линейном уровне вам нужно определить количество входящих признаков и количество исходящих признаков, которое обычно соответствует количеству классов.\n",
        "\n",
        "####Как работает нейронная сеть?\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Сеть типа **CNN** является **сетью прямого распространения**. В процессе обучения эта сеть будет обрабатывать входные данные поочередно в каждом слое и вычислять потери, обозначающие отклонение прогнозируемой метки для изображения от правильной, а также распространять градиенты обратно по сети для корректировки весовых коэффициентов в каждом слое. Повторяя этот процесс для большого набора данных, сеть постепенно \"обучается\", то есть подбирает весовые коэффициенты для достижения оптимального результата.\n",
        "\n",
        "Функция **прямого распространения** позволяет вычислить значение функции потери, а **функция обратного распространения** — градиенты параметров, по которым выполняется обучение. Когда вы создаете нейронную сеть с помощью PyTorch, вам следует определить **только** функцию прямого распространения. Функция обратного распространения будет определена **автоматически**.\n",
        "\n",
        "Пример функции прямого распространения в классе, определяющем нейронную сеть: `def forward(self, input):`\n",
        "\n",
        "**Определим класс Network для CNN:**\n"
      ],
      "metadata": {
        "id": "5psVFDIxyV66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define a convolution neural network\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(12)\n",
        "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(12)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(24)\n",
        "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(24)\n",
        "        self.fc1 = nn.Linear(24*10*10, 10)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = F.relu(self.bn1(self.conv1(input)))      \n",
        "        output = F.relu(self.bn2(self.conv2(output)))     \n",
        "        output = self.pool(output)                        \n",
        "        output = F.relu(self.bn4(self.conv4(output)))     \n",
        "        output = F.relu(self.bn5(self.conv5(output)))     \n",
        "        output = output.view(-1, 24*10*10)\n",
        "        output = self.fc1(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Instantiate a neural network model \n",
        "model = Network()"
      ],
      "metadata": {
        "id": "XeX4S1qNwiR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Определение функции потери\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Функция потери позволяет вычислить значение, которое определяет отклонение выходного значения от целевого. Основная задача нейронной сети заключается в минимизации функции потери путем корректировки значений векторных весовых коэффициентов через функцию обратного распространения.\n",
        "\n",
        "Значение потери не совпадает с точностью модели. Функция потери дает приблизительное представление о том, насколько хорошо работает модель после каждой итерации процесса оптимизации по набору для обучения. В свою очередь, точность модели вычисляется по набору для проверки и обозначает долю правильных прогнозов по нему.\n",
        "\n",
        "В PyTorch пакет нейронной сети содержит несколько разных функций потери, которые и лежат в основе создания глубоких нейронных сетей. При работе с этим руководством вы примените функцию потери \"Классификация\", которая основана на процессе определения функции потери и использует тип потери \"перекрестная энтропия\" и оптимизатор Adam. Скорость обучения позволяет задать допустимую степень изменения весовых коэффициентов в нейронной сети в отношении градиента потери. В нашем примере задайте значение 0,001. Чем ниже это значение, тем медленнее выполняется обучение."
      ],
      "metadata": {
        "id": "YRPkoFBe6v5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        " \n",
        "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
      ],
      "metadata": {
        "id": "U391wTQCyHcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Обучение модели по данным для обучения.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Чтобы обучить модель, нужно в цикле пропустить ее через итератор данных, передавая в сеть входные данные и оптимизируя ее результаты. PyTorch не предоставляет отдельной библиотеки для использования графического процессора, но вы можете вручную определить устройство для выполнения вычислений. Будет использоваться GPU Nvidia, если он установлен на вашем компьютере. Если это не так, будет использоваться обычный ЦП."
      ],
      "metadata": {
        "id": "76ay5A-x7UoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "# Function to save the model\n",
        "def saveModel():\n",
        "    path = \"./myFirstModel.pth\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "# Function to test the model with the test dataset and print the accuracy for the test images\n",
        "def testAccuracy():\n",
        "    \n",
        "    model.eval()\n",
        "    accuracy = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            # run the model on the test set to predict labels\n",
        "            outputs = model(images)\n",
        "            # the label with the highest energy will be our prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "    \n",
        "    # compute the accuracy over all test images\n",
        "    accuracy = (100 * accuracy / total)\n",
        "    return(accuracy)\n",
        "\n",
        "\n",
        "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
        "def train(num_epochs):\n",
        "    \n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    # Define your execution device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"The model will be running on\", device, \"device\")\n",
        "    # Convert model parameters and buffers to CPU or Cuda\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader, 0):\n",
        "            \n",
        "            # get the inputs\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # predict classes using images from the training set\n",
        "            outputs = model(images)\n",
        "            # compute the loss based on model output and real labels\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # backpropagate the loss\n",
        "            loss.backward()\n",
        "            # adjust parameters based on the calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Let's print statistics for every 1,000 images\n",
        "            running_loss += loss.item()     # extract the loss value\n",
        "            if i % 1000 == 999:    \n",
        "                # print every 1000 (twice per epoch) \n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 1000))\n",
        "                # zero the loss\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images\n",
        "        accuracy = testAccuracy()\n",
        "        print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
        "        \n",
        "        # we want to save the model if the accuracy is the best\n",
        "        if accuracy > best_accuracy:\n",
        "            saveModel()\n",
        "            best_accuracy = accuracy"
      ],
      "metadata": {
        "id": "gwK1eQN47O-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Протестируйте модель по данным для проверки.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Теперь вы можете проверить модель по набору изображений из набора для проверки."
      ],
      "metadata": {
        "id": "dWV-XKBr7tsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Function to show the images\n",
        "def imageshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Function to test the model with a batch of images and show the labels predictions\n",
        "def testBatch():\n",
        "    # get batch of images from the test DataLoader  \n",
        "    images, labels = next(iter(test_loader))\n",
        "\n",
        "    # show all images as one image grid\n",
        "    imageshow(torchvision.utils.make_grid(images))\n",
        "   \n",
        "    # Show the real labels on the screen \n",
        "    print('Real labels: ', ' '.join('%5s' % classes[labels[j]] \n",
        "                               for j in range(batch_size)))\n",
        "  \n",
        "    # Let's see what if the model identifiers the  labels of those example\n",
        "    outputs = model(images)\n",
        "    \n",
        "    # We got the probability for every 10 labels. The highest (max) probability should be correct label\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    \n",
        "    # Let's show the predicted labels on the screen to compare with the real ones\n",
        "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] \n",
        "                              for j in range(batch_size)))"
      ],
      "metadata": {
        "id": "TyBDFUSW7pdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Необязательно** — добавьте приведенную ниже функцию `testClassess` в файл `PyTorchTraining.py` и вызов этой функции `testClassess()` в функции main: `__name__ == \"__main__\".`"
      ],
      "metadata": {
        "id": "3Rdffwqi8V-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to test what classes performed well\n",
        "def testClassess():\n",
        "    class_correct = list(0. for i in range(number_of_labels))\n",
        "    class_total = list(0. for i in range(number_of_labels))\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            c = (predicted == labels).squeeze()\n",
        "            for i in range(batch_size):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "    for i in range(number_of_labels):\n",
        "        print('Accuracy of %5s : %2d %%' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "metadata": {
        "id": "9-Kw0kIy8RHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Uc0ghWxH7x9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    # Let's build our model\n",
        "    train(5)\n",
        "    print('Finished Training')\n",
        "\n",
        "    # Test which classes performed well\n",
        "    testModelAccuracy()\n",
        "    \n",
        "    # Let's load the model we just created and test the accuracy per label\n",
        "    model = Network()\n",
        "    path = \"myFirstModel.pth\"\n",
        "    model.load_state_dict(torch.load(path))\n",
        "\n",
        "    # Test with batch of images\n",
        "    testBatch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRoVa73X7pFi",
        "outputId": "fd269b8b-d6a2-4c22-d0e4-551bba5d1034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model will be running on cpu device\n",
            "[1,  1000] loss: 1.784\n",
            "[1,  2000] loss: 1.460\n",
            "[1,  3000] loss: 1.317\n",
            "[1,  4000] loss: 1.211\n",
            "[1,  5000] loss: 1.135\n",
            "For epoch 1 the test accuracy over the whole test set is 63 %\n",
            "[2,  1000] loss: 1.069\n",
            "[2,  2000] loss: 1.042\n",
            "[2,  3000] loss: 1.000\n",
            "[2,  4000] loss: 0.985\n",
            "[2,  5000] loss: 0.971\n",
            "For epoch 2 the test accuracy over the whole test set is 65 %\n",
            "[3,  1000] loss: 0.896\n",
            "[3,  2000] loss: 0.875\n",
            "[3,  3000] loss: 0.876\n",
            "[3,  4000] loss: 0.896\n",
            "[3,  5000] loss: 0.858\n",
            "For epoch 3 the test accuracy over the whole test set is 68 %\n",
            "[4,  1000] loss: 0.796\n",
            "[4,  2000] loss: 0.785\n",
            "[4,  3000] loss: 0.815\n",
            "[4,  4000] loss: 0.815\n"
          ]
        }
      ]
    }
  ]
}